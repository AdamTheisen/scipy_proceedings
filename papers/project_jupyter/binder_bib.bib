
@MISC{JupyterHub2018-ek,
  title       = "binder-billing",
  author      = "{JupyterHub}",
  abstract    = "GitHub is where people build software. More than 27 million
                 people use GitHub to discover, fork, and contribute to over 80
                 million projects.",
  institution = "Github",
  year        =  2018,
  url         = "https://github.com/jupyterhub/binder-billing"
}

@MISC{Atlassian_undated-ra,
  title        = "Bitbucket",
  booktitle    = "Bitbucket",
  author       = "{Atlassian}",
  abstract     = "Collaborate on code with inline comments and pull requests.
                  Manage and share your Git repositories to build and ship
                  software, as a team.",
  url          = "https://bitbucket.org",
  howpublished = "\url{https://bitbucket.org}",
  note         = "Accessed: 2018-5-24"
}

@MISC{GitHub_undated-wa,
  title       = "{GitHub}",
  author      = "{GitHub}",
  abstract    = "GitHub is where people build software. More than 27 million
                 people use GitHub to discover, fork, and contribute to over 80
                 million projects.",
  institution = "Github",
  url         = "https://github.com"
}

@MISC{Docker_Inc_undated-ai,
  title        = "Docker",
  booktitle    = "Docker",
  author       = "{Docker, Inc.}",
  abstract     = "Docker is an open platform for developers and sysadmins to
                  build, ship, and run distributed applications, whether on
                  laptops, data center VMs, or the cloud.",
  url          = "https://www.docker.com/",
  howpublished = "\url{https://www.docker.com/}",
  note         = "Accessed: 2018-5-24"
}

@MISC{Open_Humans_Foundation_undated-ov,
  title        = "Personal Data Notebooks",
  booktitle    = "Open Humans",
  author       = "{Open Humans Foundation}",
  url          = "https://www.openhumans.org/activity/personal-data-notebooks/",
  howpublished = "\url{https://www.openhumans.org/activity/personal-data-notebooks/}",
  note         = "Accessed: 2018-5-24"
}

@MISC{Head2018-jf,
  title       = "openrefineder",
  author      = "Head, Tim",
  abstract    = "GitHub is where people build software. More than 27 million
                 people use GitHub to discover, fork, and contribute to over 80
                 million projects.",
  institution = "Github",
  year        =  2018,
  url         = "https://github.com/betatim/openrefineder"
}

@MISC{RK_Min2018-eq,
  title       = "nbstencilaproxy",
  author      = "{RK, Min} and N{\"u}st, Daniel",
  abstract    = "GitHub is where people build software. More than 27 million
                 people use GitHub to discover, fork, and contribute to over 80
                 million projects.",
  institution = "Github",
  year        =  2018,
  url         = "https://github.com/minrk/nbstencilaproxy"
}

@MISC{Project_Juptyer_Contributors2017-ra,
  title    = "Using {R} with Jupyter / {RStudio} on Binder",
  author   = "{Project Juptyer Contributors}",
  year     =  2017,
  url      = "https://github.com/binder-examples/r"
}

@MISC{Project_Jupyter_Contributors2017-yi,
  title    = "jupyterlab-demo",
  author   = "{Project Jupyter Contributors}",
  year     =  2017,
  url      = "https://github.com/jupyterlab/jupyterlab-demo"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Bussonnier2018-kc,
  title        = "{I} Python, You R, We Julia",
  booktitle    = "Medium",
  author       = "Bussonnier, Matthias",
  abstract     = "When we decided to rename part of the IPython project to
                  Jupyter in 2014, we had many good reasons. Our goal was to
                  make (Data)Science and Education better, by providing Free
                  and Open-Source toolsâ€¦",
  publisher    = "Medium",
  month        =  apr,
  year         =  2018,
  url          = "https://medium.com/@mbussonn/baf064ca1fb6",
  howpublished = "\url{https://medium.com/@mbussonn/baf064ca1fb6}",
  note         = "Accessed: 2018-5-23"
}

@MISC{Cloud_Native_Computing_Foundation_undated-fl,
  title    = "Kubernetes",
  author   = "{Cloud Native Computing Foundation}",
  url      = "https://kubernetes.io/"
}

@MISC{Berkeley_Division_of_Data_Sciences_undated-nz,
  title        = "Foundations of Data Science",
  booktitle    = "data8",
  author       = "{Berkeley Division of Data Sciences}",
  url          = "http://data8.org/",
  howpublished = "\url{http://data8.org/}",
  note         = "Accessed: 2018-5-23"
}

@MISC{Wikimedia_undated-si,
  title        = "{PAWS}: A Web Shell",
  author       = "{Wikimedia}",
  url          = "https://wikitech.wikimedia.org/wiki/PAWS",
  howpublished = "\url{https://wikitech.wikimedia.org/wiki/PAWS}",
  note         = "Accessed: 2018-5-23"
}

@MISC{Microsoft_undated-gd,
  title    = "Microsoft {R} Application Network",
  author   = "{Microsoft}",
  url      = "https://mran.microsoft.com/"
}

@MISC{Nteract_contributors2016-dg,
  title    = "nteract",
  author   = "{nteract contributors}",
  abstract = "nteract is a desktop application that allows you to develop rich
              documents that contain prose, executable code, and images.",
  year     =  2016,
  url      = "https://play.nteract.io/"
}

@MISC{noauthor_undated-ux,
  title        = "Binder Grafana board",
  booktitle    = "Grafana",
  url          = "https://grafana.mybinder.org/?orgId=1",
  howpublished = "\url{https://grafana.mybinder.org/?orgId=1}",
  note         = "Accessed: 2018-5-23"
}

@INCOLLECTION{Adhikari_undated-jh,
  title     = "Plotting the Classics",
  booktitle = "Computational and Inferential Thinking",
  author    = "Adhikari, Ani and Denero, John",
  editor    = "Adhikari, Ani and Denero, John",
  url       = "https://www.inferentialthinking.com/chapters/01/3/plotting-the-classics.html"
}

@MISC{Najera_undated-uy,
  title        = "Configuration --- {Sphinx-Gallery} 0.1.13-git documentation",
  booktitle    = "{Sphinx-Gallery}",
  author       = "N{\'a}jera, {\'O}scar",
  url          = "https://sphinx-gallery.readthedocs.io/en/latest/advanced_configuration.html#binder-links",
  howpublished = "\url{https://sphinx-gallery.readthedocs.io/en/latest/advanced_configuration.html#binder-links}",
  note         = "Accessed: 2018-5-23"
}

@BOOK{Downey2016-hx,
  title     = "Think {DSP}: Digital Signal Processing in Python",
  author    = "Downey, Allen B",
  publisher = "O'Reilly Media",
  edition   = "1 edition",
  month     =  aug,
  year      =  2016,
  url       = "https://www.amazon.com/gp/product/1491938455/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491938455&linkCode=as2&tag=greenteapre01-20&linkId=CTV7PDT7E5EGGJUM",
  language  = "en"
}

@MISC{GESIS_Leibniz_Institute_for_the_Social_Sciences_undated-sn,
  title        = "{GESIS} Notebooks (beta)",
  author       = "{GESIS -- Leibniz Institute for the Social Sciences}",
  abstract     = "GESIS Notebooks (beta)",
  url          = "https://notebooks.gesis.org/",
  howpublished = "\url{https://notebooks.gesis.org/}",
  note         = "Accessed: 2018-5-23"
}

@ARTICLE{V_Stodden_D_H_Bailey_J_Borwein_R_J_LeVeque_W_Rider_and_W_Stein2012-ox,
  title   = "Setting the Default to Reproducible",
  author  = "{V. Stodden, D. H. Bailey, J. Borwein, R. J. LeVeque, W. Rider,
             and W. Stein}",
  journal = "Reproducibility in Computational and Experimental Mathematics",
  year    =  2012,
  url     = "https://www.carma.newcastle.edu.au/jon/icerm12.pdf"
}

@ARTICLE{Somers2018-bj,
  title    = "The Scientific Paper Is Obsolete",
  author   = "Somers, James",
  abstract = "Here's what's next.",
  journal  = "The Atlantic",
  month    =  apr,
  year     =  2018,
  url      = "https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/"
}

@ARTICLE{Gentleman2007-cz,
  title     = "Statistical Analyses and Reproducible Research",
  author    = "Gentleman, Robert and Lang, Duncan Temple",
  abstract  = "It is important, if not essential, to integrate the computations
               and code used in data analyses, methodological descriptions,
               simulations, and so on with the documents that describe and rely
               on them. This integration allows readers to both verify and
               adapt the claims in the documents. Authors can easily reproduce
               the results in the future, and they can present the document's
               contents in a different medium, for example, with interactive
               controls. This article describes a software framework for both
               authoring and distributing these integrated, dynamic documents
               that contain text, code, data, and any auxiliary content needed
               to recreate the computations. The documents are dynamic in that
               the contents---including figures, tables, and so on---can be
               recalculated each time a view of the document is generated. Our
               model treats a dynamic document as a master or ``source''
               document from which one can generate different views in the form
               of traditional, derived documents for different audiences. We
               introduce the concept of a compendium as a container for one or
               more dynamic documents and the different elements needed when
               processing them, such as code and data. The compendium serves as
               a means for distributing, managing, and updating the collection.
               The step from disseminating analyses via a compendium to
               reproducible research is a small one. By reproducible research,
               we mean research papers with accompanying software tools that
               allow the reader to directly reproduce the results and employ
               the computational methods that are presented in the research
               paper. Some of the issues involved in paradigms for the
               production, distribution, and use of such reproducible research
               are discussed.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  16,
  number    =  1,
  pages     = "1--23",
  year      =  2007,
  url       = "http://www.jstor.org/stable/27594227"
}

@ARTICLE{Collberg2014-hh,
  title   = "Measuring reproducibility in computer systems research",
  author  = "Collberg, Christian and Proebsting, Todd and Moraila, Gina and
             Shankaran, Akash and Shi, Zuoming and Warren, Alex M",
  journal = "Department of Computer Science, University of Arizona, Tech. Rep",
  volume  =  37,
  year    =  2014,
  url     = "http://reproducibility.cs.arizona.edu/tr.pdf"
}

@MISC{Stodden_undated-fd,
  title        = "2014 : {WHAT} {SCIENTIFIC} {IDEA} {IS} {READY} {FOR}
                  {RETIREMENT}?",
  booktitle    = "Edge",
  author       = "Stodden, Victoria",
  url          = "https://www.edge.org/response-detail/25340",
  howpublished = "\url{https://www.edge.org/response-detail/25340}",
  note         = "Accessed: 2018-5-23"
}

@ARTICLE{Stodden2018-fy,
  title    = "An empirical analysis of journal policy effectiveness for
              computational reproducibility",
  author   = "Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun",
  abstract = "A key component of scientific communication is sufficient
              information for other researchers in the field to reproduce
              published findings. For computational and data-enabled research,
              this has often been interpreted to mean making available the raw
              data from which results were generated, the computer code that
              generated the findings, and any additional information needed
              such as workflows and input parameters. Many journals are
              revising author guidelines to include data and code availability.
              This work evaluates the effectiveness of journal policy that
              requires the data and code necessary for reproducibility be made
              available postpublication by the authors upon request. We assess
              the effectiveness of such a policy by (i) requesting data and
              code from authors and (ii) attempting replication of the
              published findings. We chose a random sample of 204 scientific
              papers published in the journal Science after the implementation
              of their policy in February 2011. We found that we were able to
              obtain artifacts from 44\% of our sample and were able to
              reproduce the findings for 26\%. We find this policy-author
              remission of data and code postpublication upon request-an
              improvement over no policy, but currently insufficient for
              reproducibility.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  115,
  number   =  11,
  pages    = "2584--2589",
  month    =  mar,
  year     =  2018,
  url      = "http://dx.doi.org/10.1073/pnas.1708290115",
  keywords = "code access; data access; open science; reproducibility policy;
              reproducible research",
  language = "en"
}

@INPROCEEDINGS{Stodden2012-sd,
  title     = "{RunMyCode.org}: A novel dissemination and collaboration
               platform for executing published computational results",
  booktitle = "2012 {IEEE} 8th International Conference on {E-Science}",
  author    = "Stodden, V and Hurlin, C and P{\'e}rignon, C",
  abstract  = "We believe computational science as practiced today suffers from
               a growing credibility gap - it is impossible to replicate most
               of the computational results presented at conferences or
               published in papers today. We argue that this crisis can be
               addressed by the open availability of the code and data that
               generated the results, in other words practicing reproducible
               computational science. In this paper we present a new
               computational infrastructure called RunMyCode.org that is
               designed to support published articles by providing a
               dissemination platform for the code and data that generated the
               their results. Published articles are given a companion webpage
               on the RunMyCode.org website from which a visitor can both
               download the associated code and data, and execute the code in
               the cloud directly through the RunMyCode.org website. This
               permits results to be verified through the companion webpage or
               on a user's local system. RunMyCode.org also permits a user to
               upload their own data to the companion webpage to check the code
               by running it on novel datasets. Through the creation of ``coder
               pages'' for each contributor to RunMyCode.org, we seek to
               facilitate social network-like interaction. Descriptive
               information appears on each coder page, including demographic
               data and other companion pages to which they made contributions.
               In this paper we motivate the rationale and functionality of
               RunMyCode.org and outline a vision of its future.",
  pages     = "1--8",
  month     =  oct,
  year      =  2012,
  url       = "http://dx.doi.org/10.1109/eScience.2012.6404455",
  keywords  = "groupware;information dissemination;natural sciences
               computing;social networking (online);RunMyCode.org Website;coder
               pages;collaboration platform;companion webpage;computational
               science;credibility gap;demographic data;dissemination
               platform;published computational results;social network-like
               interaction;Collaboration;Computers;Economics;Educational
               institutions;Mathematics;Scientific computing;Software;cloud
               computing;code sharing;collaborative networks;data
               sharing;dissemination platform;executable papers;open
               science;reproducible computational science;reproducible research"
}

@ARTICLE{Anjos2017-vb,
  title         = "{BEAT}: An {Open-Source} {Web-Based} {Open-Science} Platform",
  author        = "Anjos, Andr{\'e} and El-Shafey, Laurent and Marcel,
                   S{\'e}bastien",
  abstract      = "With the increased interest in computational sciences,
                   machine learning (ML), pattern recognition (PR) and big
                   data, governmental agencies, academia and manufacturers are
                   overwhelmed by the constant influx of new algorithms and
                   techniques promising improved performance, generalization
                   and robustness. Sadly, result reproducibility is often an
                   overlooked feature accompanying original research
                   publications, competitions and benchmark evaluations. The
                   main reasons behind such a gap arise from natural
                   complications in research and development in this area: the
                   distribution of data may be a sensitive issue; software
                   frameworks are difficult to install and maintain; Test
                   protocols may involve a potentially large set of intricate
                   steps which are difficult to handle. Given the raising
                   complexity of research challenges and the constant increase
                   in data volume, the conditions for achieving reproducible
                   research in the domain are also increasingly difficult to
                   meet. To bridge this gap, we built an open platform for
                   research in computational sciences related to pattern
                   recognition and machine learning, to help on the
                   development, reproducibility and certification of results
                   obtained in the field. By making use of such a system,
                   academic, governmental or industrial organizations enable
                   users to easily and socially develop processing toolchains,
                   re-use data, algorithms, workflows and compare results from
                   distinct algorithms and/or parameterizations with minimal
                   effort. This article presents such a platform and discusses
                   some of its key features, uses and limitations. We overview
                   a currently operational prototype and provide design
                   insights.",
  month         =  apr,
  year          =  2017,
  url           = "http://arxiv.org/abs/1704.02319",
  archivePrefix = "arXiv",
  primaryClass  = "cs.SE",
  eprint        = "1704.02319"
}

@INCOLLECTION{Buckheit1995-ox,
  title     = "{WaveLab} and Reproducible Research",
  booktitle = "Wavelets and Statistics",
  author    = "Buckheit, Jonathan B and Donoho, David L",
  editor    = "Antoniadis, Anestis and Oppenheim, Georges",
  abstract  = "Wavelab is a library of wavelet-packet analysis, cosine-packet
               analysis and matching pursuit. The library is available free of
               charge over the Internet. Versions are provided for Macintosh,
               UNIX and Windows machines.",
  publisher = "Springer New York",
  pages     = "55--81",
  year      =  1995,
  url       = "https://doi.org/10.1007/978-1-4612-2544-7_5",
  address   = "New York, NY"
}

@MISC{Project_Jupyter_Contributors2017-dn,
  title       = "example-conda-environment",
  author      = "{Project Jupyter Contributors}",
  abstract    = "example-conda-environment - An example Binder repository that
                 contains an environment.yml file",
  institution = "Github",
  year        =  2017,
  url         = "https://github.com/binder-project/example-conda-environment"
}

@MISC{Project_Jupyter_Contributors2017-no,
  title       = "repo2docker",
  author      = "{Project Jupyter Contributors}",
  institution = "Github",
  year        =  2017,
  url         = "https://github.com/jupyter/repo2docker/"
}

@MISC{LIGO_Scientific_Collaboration_undated-xy,
  title        = "{LIGO} Open Science Center",
  booktitle    = "{LIGO}",
  author       = "{LIGO Scientific Collaboration}",
  url          = "https://losc.ligo.org/tutorials/",
  howpublished = "\url{https://losc.ligo.org/tutorials/}",
  note         = "Accessed: 2017-12-12"
}

@ARTICLE{Doshi-Velez2017-ax,
  title         = "Towards A Rigorous Science of Interpretable Machine Learning",
  author        = "Doshi-Velez, Finale and Kim, Been",
  abstract      = "As machine learning systems become ubiquitous, there has
                   been a surge of interest in interpretable machine learning:
                   systems that provide explanation for their outputs. These
                   explanations are often used to qualitatively assess other
                   criteria such as safety or non-discrimination. However,
                   despite the interest in interpretability, there is very
                   little consensus on what interpretable machine learning is
                   and how it should be measured. In this position paper, we
                   first define interpretability and describe when
                   interpretability is needed (and when it is not). Next, we
                   suggest a taxonomy for rigorous evaluation and expose open
                   questions towards a more rigorous science of interpretable
                   machine learning.",
  month         =  feb,
  year          =  2017,
  url           = "http://arxiv.org/abs/1702.08608",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML",
  eprint        = "1702.08608"
}

@MISC{Project_Jupyter_Contributors_undated-zb,
  title       = "Juptyer Notebook",
  author      = "{Project Jupyter Contributors}",
  abstract    = "notebook - Jupyter Interactive Notebook",
  institution = "Github",
  url         = "https://github.com/jupyter/notebook"
}

@MANUAL{Project_Jupyter_Contributors_undated-sp,
  title        = "Jupyter kernels",
  author       = "{Project Jupyter Contributors}",
  abstract     = "jupyter - Jupyter metapackage for installation, docs and chat",
  url          = "https://github.com/jupyter/jupyter/wiki/Jupyter-kernels",
  organization = "Project Jupyter"
}

@INPROCEEDINGS{Ross2017-ff,
  title           = "Right for the Right Reasons: Training Differentiable
                     Models by Constraining their Explanations",
  booktitle       = "Proceedings of the {Twenty-Sixth} International Joint
                     Conference on Artificial Intelligence",
  author          = "Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez,
                     Finale",
  abstract        = "Neural networks are among the most accurate supervised
                     learning methods in use today, but their opacity makes
                     them difficult to trust in critical applications,
                     especially when conditions in training differ from those
                     in test. Recent work on explanations for black-box models
                     has produced tools (e.g. LIME) to show the implicit rules
                     behind predictions, which can help us identify when models
                     are right for the wrong reasons. However, these methods do
                     not scale to explaining entire datasets and cannot correct
                     the problems they reveal. We introduce a method for
                     efficiently explaining and regularizing differentiable
                     models by examining and selectively penalizing their input
                     gradients, which provide a normal to the decision
                     boundary. We apply these penalties both based on expert
                     annotation and in an unsupervised fashion that encourages
                     diverse models with qualitatively different decision
                     boundaries for the same classification problem. On
                     multiple datasets, we show our approach generates faithful
                     explanations and models that generalize much better when
                     conditions differ between training and test.",
  pages           = "Pages 2662--2670.",
  month           =  mar,
  year            =  2017,
  url             = "https://www.ijcai.org/proceedings/2017/371",
  conference      = "International Joint Conference on Artificial Intelligence"
}

@MISC{Liang2015-ay,
  title      = "{CodaLab} Worksheets for Reproducible, Executable Papers",
  author     = "Liang, Percy and Viegas, Evelyne",
  abstract   = "We are interested in solving two infrastructural problems in
                data-centric fields such as machine learning: First, an
                inordinate amount of time is spent on preprocessing datasets,
                getting other people's code to run, writing
                evaluation/visualization scripts, with much of this effort
                duplicated across different research groups. Second, a only
                static set of final results are ever published, leaving it up
                to the reader to guess how the various methods would fare in
                unreported scenarios. We present CodaLab Worksheets, a new
                platform which aims to tackle these two problems by creating an
                online community around sharing and executing immutable
                components called bundles, thereby streamlining the research
                process.",
  month      =  dec,
  year       =  2015,
  url        = "https://nips.cc/Conferences/2015/Schedule?showEvent=5779",
  conference = "NIPS 2015, Demonstrations Track"
}

@ARTICLE{Erin_D_Foster2017-tk,
  title     = "Open Science Framework ({OSF})",
  author    = "Erin D. Foster, Ariel Deardorff",
  journal   = "J. Med. Libr. Assoc.",
  publisher = "Medical Library Association",
  volume    =  105,
  number    =  2,
  pages     = "203",
  month     =  apr,
  year      =  2017,
  url       = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/",
  language  = "en"
}

@MISC{Freeman2016-jt,
  title        = "Toward publishing reproducible computation with Binder",
  booktitle    = "eLife",
  author       = "Freeman, Jeremy and Osheroff, Andrew",
  abstract     = "Binder makes it easy to include an interactive version of
                  your analysis, with the supporting data and code, alongside a
                  published paper.",
  month        =  may,
  year         =  2016,
  url          = "https://elifesciences.org/labs/a7d53a88/toward-publishing-reproducible-computation-with-binder",
  howpublished = "\url{https://elifesciences.org/labs/a7d53a88/toward-publishing-reproducible-computation-with-binder}",
  note         = "Accessed: 2017-12-11"
}

@MISC{Project_Jupyter_Contributors_undated-jn,
  title        = "Binder (beta)",
  author       = "{Project Jupyter Contributors}",
  url          = "https://mybinder.org/",
  howpublished = "\url{https://mybinder.org/}",
  note         = "Accessed: 2017-12-11"
}

@MANUAL{Project_Jupyter_Contributors_undated-no,
  title    = "A Gallery of {JupyterHub} Deployments",
  author   = "{Project Jupyter Contributors}",
  url      = "http://jupyterhub.readthedocs.io/en/latest/gallery-jhub-deployments.html"
}

@MISC{Pineau2017-sb,
  title      = "Reproducibility in Deep Reinforcement Learning and Beyond",
  author     = "Pineau, Joelle",
  month      =  dec,
  year       =  2017,
  url        = "https://twitter.com/xtimv/status/938917013086380032",
  conference = "Deep Reinforcement Learning Symposium, NIPS 2017"
}

@MISC{Project_Jupyter_Contributors_undated-zr,
  title        = "Introducing Binder 2.0 --- share your interactive research
                  environment",
  booktitle    = "eLife",
  author       = "{Project Jupyter Contributors}",
  abstract     = "The Project Jupyter team shares its reboot of Binder, the
                  tool that allows researchers to make their GitHub
                  repositories executable by others.",
  url          = "https://elifesciences.org/labs/8653a61d/introducing-binder-2-0-share-your-interactive-research-environment",
  howpublished = "\url{https://elifesciences.org/labs/8653a61d/introducing-binder-2-0-share-your-interactive-research-environment}",
  note         = "Accessed: 2017-12-11"
}
